# MM-Skin: Enhancing Dermatology Vision-Language Model with an Image-Text Dataset Derived from Textbooks

Paper[PDF] Dataset[[Google Drive](https://drive.google.com/file/d/1oCblHgWo36OZIDovjIpl9FnKOYpsSN91/view?usp=sharing)] Code[[Github](https://github.com/ZwQ803/MM-Skin/tree/main)]

we propose MM-Skin, a large-scale multimodal dermatology dataset that encompasses 3 imaging modalities, including clinical, dermoscopic, and pathological and nearly 10k high-quality image-text pairs collected from professional textbooks and over 27k vision question answering (VQA) samples.

In addition, we developed SkinVL, a dermatology-specific VLM, and conducted comprehensive benchmark evaluations of SkinVL on VQA, supervised fine-tuning (SFT), and zero-shot classification tasks.

Code and model weights are coming soon.
